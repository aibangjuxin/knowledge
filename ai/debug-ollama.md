
æ£€æŸ¥ Ollama æœåŠ¡å™¨æ˜¯å¦æ­£å¸¸è¿è¡Œï¼Œç”¨è¿™äº›å‘½ä»¤ï¼ˆmacOS/iTerm2 ç¯å¢ƒï¼‰ï¼š

## æœ€ç®€å•å‘½ä»¤
```bash
curl http://localhost:11434
                                                                                                                                                                                       knowledge/gcp on î‚  main [?] on â˜ï¸   curl http://localhost:11434
Ollama is running%                                                                                                                                                                                                  knowledge/gcp on î‚  main [?] on â˜ï¸  ps aux | grep ollamaa

lex              70144   0.0  0.1 436764784  14416   ??  S    Sat09AM   0:02.20 /Applications/Ollama.app/Contents/Resources/ollama serve
lex              41166   0.0  0.1 437026352  17056   ??  S    15Feb26   0:42.53 /usr/local/bin/ollama serve
lex              34979   0.0  0.0 435299680   1392 s008  S+   10:28AM   0:00.01 grep --color=auto ollama
lex              34808   0.0  0.2 440574464  36864   ??  S    10:19AM   0:09.35 /Applications/Ollama.app/Contents/Resources/ollama runner --ollama-engine --model /Users/lex/.ollama/models/blobs/sha256-3e4cb14174460404e7a233e531675303b2fbf7749c02f91864fe311ab6344e4f --port 58138

~ on â˜ï¸   ollama list
NAME                               ID              SIZE      MODIFIED
MedAIBase/PaddleOCR-VL:0.9b        2d9290d5ab53    935 MB    3 weeks ago
kimi-k2.5:cloud                    6d1c3246c608    -         3 weeks ago
translategemma:4b                  c49d986b0764    3.3 GB    5 weeks ago
demonbyron/HY-MT1.5-1.8B:latest    f2ab05e35468    1.1 GB    5 weeks ago
qwen3:4b                           e55aed6fe643    2.5 GB    5 months ago
mistral:latest                     6577803aa9a0    4.4 GB    5 months ago
dimavz/whisper-tiny:latest         9aafc61ff108    44 MB     5 months ago
gemma3:270m                        e7d36fb2c3b3    291 MB    6 months ago
qwen:4b                            d53d04290064    2.3 GB    6 months ago
qwen3:4b-instruct                  088c6bc07f1d    2.5 GB    6 months ago
gpt-oss:20b                        e95023cf3b7b    13 GB     6 months ago
gemma3:4b                          a2af6cc3eb7f    3.3 GB    6 months ago
gemma3:4b-it-qat                   d01ad0579247    4.0 GB    7 months ago
qwen3:0.6b                         7df6b6e09427    522 MB    8 months ago
deepseek-r1:1.5b                   e0979632db5a    1.1 GB    8 months ago
gemma3:1b                          8648f39daa8f    815 MB    8 months ago

```
- **æ­£å¸¸è¾“å‡º**ï¼š`Ollama is running`
- **è¶…æ—¶/é”™è¯¯**ï¼šæœåŠ¡æ²¡å¯åŠ¨ã€‚

## å®Œæ•´æ£€æŸ¥æ­¥éª¤
1. **æœåŠ¡çŠ¶æ€**ï¼š
   ```bash
   ps aux | grep ollama
   ```
   çœ‹åˆ° `ollama serve` è¿›ç¨‹è¯´æ˜åœ¨è·‘ã€‚

2. **åˆ—å‡ºæ¨¡å‹**ï¼ˆç¡®è®¤ API æ­£å¸¸ï¼‰ï¼š
   ```bash
   curl http://localhost:11434/api/tags
   ```
   è¿”å› JSON æ¨¡å‹åˆ—è¡¨å³æ­£å¸¸ã€‚

3. **æµ‹è¯• Chat API**ï¼ˆiTerm2 ç”¨çš„è¿™ä¸ªï¼‰ï¼š
   ```bash
   curl http://localhost:11434/v1/chat/completions \
     -H "Content-Type: application/json" \
     -d '{"model": "qwen3:4b", "messages": [{"role": "user", "content": "hi"}]}'

     ~ on â˜ï¸     curl http://localhost:11434/v1/chat/completions \\
     -H "Content-Type: application/json" \
     -d '{"model": "qwen3:4b", "messages": [{"role": "user", "content": "hi"}]}'
{"id":"chatcmpl-564","object":"chat.completion","created":1771814010,"model":"qwen3:4b","system_fingerprint":"fp_ollama","choices":[{"index":0,"message":{"role":"assistant","content":"Hi there! ğŸ˜Š How can I help you today?","reasoning":"Okay, the user said \"hi\". That's pretty straightforward. I need to respond appropriately.\n\nFirst, I should acknowledge their greeting in a friendly manner. Since the user is just saying hello, I don't have much context to go on. My response should be warm and open-ended to encourage further interaction.\n\nMaybe I can start with something like \"Hello! How can I assist you today?\" That's standard but friendly. Wait, the user might be testing if I'm a real AI or just a bot. But they said \"hi\", so probably just starting a conversation.\n\nHmm, I should avoid any technical jargon or complex responses. Keep it simple. Let me check if there's a cultural nuance I'm missing. In some regions, \"hi\" might be used differently, but since it's English, probably safe to go with standard greeting.\n\nAlso, I need to make sure the response is helpful. Maybe add a note about being here to help. Let me structure it: Greeting + expression of being here to help. Like \"Hello! I'm here to help with anything you need. What would you like to do today?\" \n\nWait, the user might want a shorter response. But \"hi\" is a very short greeting, so they might expect a concise reply. Let me check examples of AI responses. For instance, some AIs start with \"Hey there! ğŸ‘‹ How can I help you today?\" \n\nBut in this case, the user said \"hi\", so maybe a bit more casual. Let me go with a friendly and approachable tone. \n\nI think the best approach is to greet them back and ask how I can assist. So the response would be: \"Hi there! ğŸ˜Š How can I help you today?\"\n\nWait, the user might not need a whole sentence, but since it's a greeting, adding a question to move the conversation forward makes sense. Let me write that.\n\nDouble-checking for any typos. Yep, \"Hi there! ğŸ˜Š How can I help you today?\" looks good. The emoji adds a friendly touch without being too much. The user probably expects a polite and helpful response.\n\nI think that's a good response. Let me make sure it's not too long. The original message is just \"hi\", so a short response is better. Yeah, that's concise and friendly.\n"},"finish_reason":"stop"}],"usage":{"prompt_tokens":9,"completion_tokens":496,"total_tokens":505}}


curl http://localhost:11434/v1/chat/completions \
     -H "Content-Type: application/json" \
     -d '{"model": "gemma3:1b", "messages": [{"role": "user", "content": "hi"}]}'
   ```
   è¿”å› JSON å“åº”å°±å®Œç¾ã€‚

## å¯åŠ¨æœåŠ¡ï¼ˆå¦‚æœæ²¡è·‘ï¼‰
```bash
ollama serve
```
ä¿æŒè¿™ä¸ªç»ˆç«¯å¼€ç€ï¼Œæˆ–ç”¨ Ollama èœå•æ  app å¯åŠ¨ã€‚

## å¿«é€Ÿè¯Šæ–­
```bash
# ä¸€é”®å…¨æŸ¥
curl -s http://localhost:11434 && echo "âœ“ æœåŠ¡OK" || echo "âœ— æœåŠ¡å¼‚å¸¸"
ollama list && echo "âœ“ æ¨¡å‹OK" || echo "âœ— æ— æ¨¡å‹"
```
æŒ‰é¡ºåºè·‘è¿™äº›ï¼Œ90% é—®é¢˜èƒ½å®šä½ã€‚å¦‚æœ `curl http://localhost:11434` è¿”å› "Ollama is running"ï¼Œé‚£ iTerm2 è¶…æ—¶å°±æ˜¯é…ç½®é—®é¢˜äº†ã€‚ 



