- [Claude4](#claude4)
  - [ä¸»è¦è§£å†³æ–¹æ¡ˆ](#ä¸»è¦è§£å†³æ–¹æ¡ˆ)
    - [1. é˜Ÿåˆ—æ¨¡å¼ (ä½¿ç”¨ Pub/Sub)](#1-é˜Ÿåˆ—æ¨¡å¼-ä½¿ç”¨-pubsub)
    - [2. ä¸»ä»æ¨¡å¼ (Leader Election)](#2-ä¸»ä»æ¨¡å¼-leader-election)
    - [3. åˆ†ç‰‡å†™å…¥æ¨¡å¼](#3-åˆ†ç‰‡å†™å…¥æ¨¡å¼)
    - [4. äº‹åŠ¡é”æœºåˆ¶](#4-äº‹åŠ¡é”æœºåˆ¶)
    - [5. ä½¿ç”¨ StatefulSet + PVC](#5-ä½¿ç”¨-statefulset--pvc)
  - [æ¨èæ¶æ„ç»„åˆ](#æ¨èæ¶æ„ç»„åˆ)
    - [Pub/Sub + æ¶ˆè´¹è€…æ¨¡å¼ (æœ€æ¨è)](#pubsub--æ¶ˆè´¹è€…æ¨¡å¼-æœ€æ¨è)
    - [å®ç°ç¤ºä¾‹](#å®ç°ç¤ºä¾‹)
  - [æ–¹æ¡ˆå¯¹æ¯”è¡¨](#æ–¹æ¡ˆå¯¹æ¯”è¡¨)
  - [æ”¹è¿›çš„é˜Ÿåˆ—æ¨¡å¼æ¶æ„](#æ”¹è¿›çš„é˜Ÿåˆ—æ¨¡å¼æ¶æ„)
    - [1. å¤šæ¶ˆè´¹è€… + åˆ†åŒºå¤„ç†](#1-å¤šæ¶ˆè´¹è€…--åˆ†åŒºå¤„ç†)
    - [2. åŸºäºæ¶ˆæ¯å±æ€§çš„åˆ†åŒºç­–ç•¥](#2-åŸºäºæ¶ˆæ¯å±æ€§çš„åˆ†åŒºç­–ç•¥)
    - [3. æ¶ˆè´¹è€…é«˜å¯ç”¨é…ç½®](#3-æ¶ˆè´¹è€…é«˜å¯ç”¨é…ç½®)
    - [4. æ”¹è¿›çš„æ¶ˆè´¹è€…é€»è¾‘](#4-æ”¹è¿›çš„æ¶ˆè´¹è€…é€»è¾‘)
    - [5. åˆ†å¸ƒå¼é”å®ç° (ä½¿ç”¨ Redis)](#5-åˆ†å¸ƒå¼é”å®ç°-ä½¿ç”¨-redis)
  - [å®Œæ•´çš„é«˜å¯ç”¨æ¶æ„](#å®Œæ•´çš„é«˜å¯ç”¨æ¶æ„)
  - [æ•…éšœæ¢å¤æœºåˆ¶](#æ•…éšœæ¢å¤æœºåˆ¶)
  - [1. åŸºäº Session Affinity (æœ€ç®€å•)](#1-åŸºäº-session-affinity-æœ€ç®€å•)
    - [Kubernetes Service é…ç½®](#kubernetes-service-é…ç½®)
  - [2. ä½¿ç”¨ Kong å®ç°ç²¾ç¡®æµé‡æ§åˆ¶](#2-ä½¿ç”¨-kong-å®ç°ç²¾ç¡®æµé‡æ§åˆ¶)
    - [Kong æ’ä»¶é…ç½®](#kong-æ’ä»¶é…ç½®)
    - [è‡ªå®šä¹‰ Kong æ’ä»¶å®ç°](#è‡ªå®šä¹‰-kong-æ’ä»¶å®ç°)
  - [3. ä½¿ç”¨ Istio Service Mesh](#3-ä½¿ç”¨-istio-service-mesh)
    - [DestinationRule é…ç½®](#destinationrule-é…ç½®)
    - [VirtualService é…ç½®](#virtualservice-é…ç½®)
  - [4. åº”ç”¨å±‚è´Ÿè½½å‡è¡¡æ§åˆ¶](#4-åº”ç”¨å±‚è´Ÿè½½å‡è¡¡æ§åˆ¶)
    - [è‡ªå®šä¹‰è´Ÿè½½å‡è¡¡å™¨](#è‡ªå®šä¹‰è´Ÿè½½å‡è¡¡å™¨)
  - [5. åŸºäº Deployment Label çš„ç²¾ç¡®æ§åˆ¶](#5-åŸºäº-deployment-label-çš„ç²¾ç¡®æ§åˆ¶)
    - [åˆ›å»ºå¸¦æ ‡ç­¾çš„ Deployment](#åˆ›å»ºå¸¦æ ‡ç­¾çš„-deployment)
    - [å¯¹åº”çš„å¤šä¸ª Service](#å¯¹åº”çš„å¤šä¸ª-service)
  - [6. å®Œæ•´çš„æµé‡æ§åˆ¶æ¶æ„](#6-å®Œæ•´çš„æµé‡æ§åˆ¶æ¶æ„)
  - [å®ç°å»ºè®®ä¼˜å…ˆçº§](#å®ç°å»ºè®®ä¼˜å…ˆçº§)
- [ChatGPT](#chatgpt)
- [Pod A æˆåŠŸæ‹¿åˆ° Redis é”åæ‰èƒ½æ‰§è¡Œå†™æ“ä½œ](#pod-a-æˆåŠŸæ‹¿åˆ°-redis-é”åæ‰èƒ½æ‰§è¡Œå†™æ“ä½œ)
  - [**âœ… ä½¿ç”¨ Pub/Sub çš„ä¼˜åŠ¿ï¼ˆç‰¹åˆ«é€‚ç”¨äº GKEï¼‰**](#-ä½¿ç”¨-pubsub-çš„ä¼˜åŠ¿ç‰¹åˆ«é€‚ç”¨äº-gke)
  - [**ğŸ“Œ æ¨èæ¶æ„æ¨¡å¼ï¼šPub/Sub + Worker å†™å…¥ DB**](#-æ¨èæ¶æ„æ¨¡å¼pubsub--worker-å†™å…¥-db)
    - [**è¯´æ˜ï¼š**](#è¯´æ˜)
  - [**ğŸ”§ å®ç°å»ºè®®**](#-å®ç°å»ºè®®)
    - [**1.**Â ](#1)
    - [**Producer ç«¯ï¼ˆGKE API Podï¼‰**](#producer-ç«¯gke-api-pod)
    - [**2.**Â ](#2)
    - [**Consumer ç«¯ï¼ˆç‹¬ç«‹ GKE Worker æˆ– Cloud Runï¼‰**](#consumer-ç«¯ç‹¬ç«‹-gke-worker-æˆ–-cloud-run)
  - [**ğŸ§± å¯é€‰å¢å¼ºç»„ä»¶**](#-å¯é€‰å¢å¼ºç»„ä»¶)
  - [**âœ… æ€»ç»“ï¼šä¸ºä»€ä¹ˆ Pub/Sub + GKE æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é€‰æ‹©ï¼Ÿ**](#-æ€»ç»“ä¸ºä»€ä¹ˆ-pubsub--gke-æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é€‰æ‹©)
  - [**ğŸ”§ å‰æ**](#-å‰æ)
  - [**1. Python æ¶ˆè´¹è„šæœ¬ï¼ˆsubscriber.pyï¼‰**](#1-python-æ¶ˆè´¹è„šæœ¬subscriberpy)
  - [**2. Dockerfile**](#2-dockerfile)
  - [**3. GKE Deployment ç¤ºä¾‹ï¼ˆsubscriber-deployment.yamlï¼‰**](#3-gke-deployment-ç¤ºä¾‹subscriber-deploymentyaml)
  - [**4. å¯é€‰ HPA é…ç½®ï¼ˆæŒ‰ CPU æˆ–è‡ªå®šä¹‰æŒ‡æ ‡ï¼‰**](#4-å¯é€‰-hpa-é…ç½®æŒ‰-cpu-æˆ–è‡ªå®šä¹‰æŒ‡æ ‡)
  - [**5. Pub/Sub Subscription åˆ›å»ºï¼ˆå‘½ä»¤ï¼‰**](#5-pubsub-subscription-åˆ›å»ºå‘½ä»¤)
  - [**âœ… æ€»ç»“**](#-æ€»ç»“)


# Claude4

å¯¹äºå¤š Pod åŒæ—¶å†™æ•°æ®å¯èƒ½å¼•èµ·å†²çªçš„é—®é¢˜ï¼Œæœ‰å¤šç§è§£å†³æ–¹æ¡ˆã€‚ä»¥ä¸‹æ˜¯å¸¸è§çš„å‡ ç§æ¶æ„æ¨¡å¼ï¼š

## ä¸»è¦è§£å†³æ–¹æ¡ˆ

### 1. é˜Ÿåˆ—æ¨¡å¼ (ä½¿ç”¨ Pub/Sub)

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-writer
spec:
  replicas: 3
  selector:
    matchLabels:
      app: data-writer
  template:
    spec:
      containers:
        - name: writer
          image: your-app:latest
          env:
            - name: PUBSUB_SUBSCRIPTION
              value: "data-write-subscription"
```

```mermaid
graph TD
    A[APIè¯·æ±‚] --> B[Load Balancer]
    B --> C[å¤šä¸ªPodå®ä¾‹]
    C --> D[Pub/Sub Topic]
    D --> E[Subscription]
    E --> F[å•ä¸€æ¶ˆè´¹è€…Pod]
    F --> G[æ•°æ®åº“å†™å…¥]

    subgraph "GKE Cluster"
        C
        F
    end

    subgraph "GCP Services"
        D
        E
    end
```

### 2. ä¸»ä»æ¨¡å¼ (Leader Election)

```yaml
# leader-election-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: writer-with-leader
spec:
  replicas: 3
  template:
    spec:
      containers:
        - name: writer
          image: your-app:latest
          env:
            - name: LEADER_ELECTION_NAMESPACE
              value: "default"
            - name: LEADER_ELECTION_NAME
              value: "data-writer-leader"
```

```go
// ç¤ºä¾‹ä»£ç ï¼šKubernetes Leader Election
import (
    "k8s.io/client-go/tools/leaderelection"
    "k8s.io/client-go/tools/leaderelection/resourcelock"
)

func startLeaderElection() {
    lock := &resourcelock.LeaseLock{
        LeaseMeta: metav1.ObjectMeta{
            Name:      "data-writer-leader",
            Namespace: "default",
        },
    }

    leaderelection.RunOrDie(ctx, leaderelection.LeaderElectionConfig{
        Lock:          lock,
        LeaseDuration: 15 * time.Second,
        RenewDeadline: 10 * time.Second,
        RetryPeriod:   2 * time.Second,
        Callbacks: leaderelection.LeaderCallbacks{
            OnStartedLeading: func(ctx context.Context) {
                // å¼€å§‹å¤„ç†å†™æ“ä½œ
                startWriteOperations()
            },
            OnStoppedLeading: func() {
                // åœæ­¢å†™æ“ä½œ
                stopWriteOperations()
            },
        },
    })
}
```

### 3. åˆ†ç‰‡å†™å…¥æ¨¡å¼

```mermaid
graph TD
    A[APIè¯·æ±‚] --> B[Load Balancer]
    B --> C[Pod-1 åˆ†ç‰‡A]
    B --> D[Pod-2 åˆ†ç‰‡B]
    B --> E[Pod-3 åˆ†ç‰‡C]

    C --> F[æ•°æ®åº“åˆ†ç‰‡A]
    D --> G[æ•°æ®åº“åˆ†ç‰‡B]
    E --> H[æ•°æ®åº“åˆ†ç‰‡C]

    subgraph "æ•°æ®åˆ†ç‰‡ç­–ç•¥"
        I[åŸºäºç”¨æˆ·ID]
        J[åŸºäºæ—¶é—´èŒƒå›´]
        K[åŸºäºæ•°æ®ç±»å‹]
    end
```

### 4. äº‹åŠ¡é”æœºåˆ¶

```sql
-- æ•°æ®åº“å±‚é¢çš„é”æœºåˆ¶
BEGIN TRANSACTION;

-- è·å–è¡Œé”æˆ–è¡¨é”
SELECT * FROM data_table WHERE id = ? FOR UPDATE;

-- æ‰§è¡Œå†™æ“ä½œ
UPDATE data_table SET value = ? WHERE id = ?;

COMMIT;
```

### 5. ä½¿ç”¨ StatefulSet + PVC

```yaml
# statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: data-writer
spec:
  serviceName: "data-writer"
  replicas: 3
  template:
    spec:
      containers:
        - name: writer
          image: your-app:latest
          volumeMounts:
            - name: data-storage
              mountPath: /data
  volumeClaimTemplates:
    - metadata:
        name: data-storage
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 10Gi
```

## æ¨èæ¶æ„ç»„åˆ

### Pub/Sub + æ¶ˆè´¹è€…æ¨¡å¼ (æœ€æ¨è)

```mermaid
flowchart TD
    A[Client Request] --> B[API Gateway/Kong]
    B --> C[Write API Pods]
    C --> D[Pub/Sub Topic]

    D --> E[Subscription-1]
    D --> F[Subscription-2]

    E --> G[Consumer Pod-1]
    F --> H[Consumer Pod-2]

    G --> I[Database Shard-1]
    H --> J[Database Shard-2]

    subgraph "GKE Cluster"
        C
        G
        H
    end

    subgraph "GCP Managed Services"
        D
        E
        F
    end

    subgraph "Database Layer"
        I
        J
    end
```

### å®ç°ç¤ºä¾‹

```go
// Producer (API Pod)
func writeDataHandler(w http.ResponseWriter, r *http.Request) {
    data := extractDataFromRequest(r)

    // å‘é€åˆ° Pub/Sub è€Œä¸æ˜¯ç›´æ¥å†™æ•°æ®åº“
    message := &pubsub.Message{
        Data: json.Marshal(data),
        Attributes: map[string]string{
            "operation": "insert",
            "timestamp": time.Now().Format(time.RFC3339),
        },
    }

    result := topic.Publish(ctx, message)
    if _, err := result.Get(ctx); err != nil {
        http.Error(w, "Failed to publish message", 500)
        return
    }

    w.WriteHeader(http.StatusAccepted)
    json.NewEncoder(w).Encode(map[string]string{"status": "queued"})
}

// Consumer (Background Worker Pod)
func startConsumer() {
    subscription.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {
        var data DataStruct
        if err := json.Unmarshal(msg.Data, &data); err != nil {
            msg.Nack()
            return
        }

        // ä¸²è¡ŒåŒ–å†™å…¥æ•°æ®åº“
        if err := writeToDatabase(data); err != nil {
            msg.Nack()
            return
        }

        msg.Ack()
    })
}
```

## æ–¹æ¡ˆå¯¹æ¯”è¡¨

| æ–¹æ¡ˆ            | é«˜å¯ç”¨æ€§ | æ•°æ®ä¸€è‡´æ€§ | å¤æ‚åº¦ | æ€§èƒ½  | é€‚ç”¨åœºæ™¯     |
| --------------- | -------- | ---------- | ------ | ----- | ------------ |
| Pub/Sub é˜Ÿåˆ—    | âœ… é«˜    | âœ… å¼º      | ğŸŸ¡ ä¸­  | âœ… é«˜ | å¼‚æ­¥å†™å…¥åœºæ™¯ |
| Leader Election | âœ… é«˜    | âœ… å¼º      | ğŸŸ¡ ä¸­  | ğŸ”´ ä½ | ç®€å•å†™å…¥åœºæ™¯ |
| æ•°æ®åˆ†ç‰‡        | âœ… é«˜    | âœ… å¼º      | ğŸ”´ é«˜  | âœ… é«˜ | å¤§æ•°æ®é‡åœºæ™¯ |
| æ•°æ®åº“é”        | ğŸŸ¡ ä¸­    | âœ… å¼º      | ğŸŸ¢ ä½  | ğŸ”´ ä½ | å°å¹¶å‘åœºæ™¯   |
| StatefulSet     | ğŸŸ¡ ä¸­    | âœ… å¼º      | ğŸŸ¡ ä¸­  | ğŸŸ¡ ä¸­ | æœ‰çŠ¶æ€åº”ç”¨   |

å¯¹äºç”Ÿäº§ç¯å¢ƒï¼Œ**æ¨èä½¿ç”¨ Pub/Sub + æ¶ˆè´¹è€…æ¨¡å¼**ï¼Œæ—¢ä¿è¯äº†é«˜å¯ç”¨æ€§ï¼Œåˆé¿å…äº†æ•°æ®å†²çªï¼ŒåŒæ—¶ä¿æŒäº†è‰¯å¥½çš„æ€§èƒ½å’Œæ‰©å±•æ€§ã€‚

ç¡®å®ï¼Œå•ä¸€æ¶ˆè´¹è€… Pod ä»ç„¶æ˜¯å•ç‚¹é—®é¢˜ï¼è¿™æ˜¯ä¸ªå¾ˆå¥½çš„è§‚å¯Ÿã€‚è®©æˆ‘é‡æ–°è®¾è®¡æ›´å®Œå–„çš„æ–¹æ¡ˆï¼š

## æ”¹è¿›çš„é˜Ÿåˆ—æ¨¡å¼æ¶æ„

### 1. å¤šæ¶ˆè´¹è€… + åˆ†åŒºå¤„ç†

```mermaid
flowchart TD
    A[APIè¯·æ±‚] --> B[Kong Gateway]
    B --> C[å†™å…¥API Pods]
    C --> D[Pub/Sub Topic with Partitions]

    D --> E[Subscription-1<br/>Partition: user_id % 3 = 0]
    D --> F[Subscription-2<br/>Partition: user_id % 3 = 1]
    D --> G[Subscription-3<br/>Partition: user_id % 3 = 2]

    E --> H[Consumer Pod-1<br/>HPA: 2-5 replicas]
    F --> I[Consumer Pod-2<br/>HPA: 2-5 replicas]
    G --> J[Consumer Pod-3<br/>HPA: 2-5 replicas]

    H --> K[Database Shard-1]
    I --> L[Database Shard-2]
    J --> M[Database Shard-3]

    subgraph "GKE Cluster"
        C
        H
        I
        J
    end

    subgraph "GCP Pub/Sub"
        D
        E
        F
        G
    end
```

### 2. åŸºäºæ¶ˆæ¯å±æ€§çš„åˆ†åŒºç­–ç•¥

```go
// Producer: å‘é€å¸¦åˆ†åŒºé”®çš„æ¶ˆæ¯
func publishMessage(data WriteRequest) error {
    // åŸºäºä¸šåŠ¡é€»è¾‘ç¡®å®šåˆ†åŒºé”®
    partitionKey := generatePartitionKey(data)

    message := &pubsub.Message{
        Data: json.Marshal(data),
        Attributes: map[string]string{
            "partition_key": partitionKey,
            "message_type": data.Type,
            "timestamp":    time.Now().Format(time.RFC3339),
        },
        OrderingKey: partitionKey, // ç¡®ä¿åŒä¸€åˆ†åŒºçš„æ¶ˆæ¯æœ‰åº
    }

    result := topic.Publish(ctx, message)
    return result.Get(ctx)
}

func generatePartitionKey(data WriteRequest) string {
    switch data.Type {
    case "user_data":
        return fmt.Sprintf("user_%d", data.UserID%3)
    case "order_data":
        return fmt.Sprintf("order_%s", data.OrderID[:2])
    default:
        return fmt.Sprintf("default_%d", time.Now().Unix()%3)
    }
}
```

### 3. æ¶ˆè´¹è€…é«˜å¯ç”¨é…ç½®

```yaml
# consumer-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-consumer-shard-1
spec:
  replicas: 2 # æœ€å°‘2ä¸ªå‰¯æœ¬
  selector:
    matchLabels:
      app: data-consumer
      shard: "1"
  template:
    metadata:
      labels:
        app: data-consumer
        shard: "1"
    spec:
      containers:
        - name: consumer
          image: your-consumer:latest
          env:
            - name: SUBSCRIPTION_NAME
              value: "data-write-subscription-shard-1"
            - name: SHARD_ID
              value: "1"
            - name: MAX_CONCURRENT_HANDLERS
              value: "10"
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 500m
              memory: 512Mi
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /ready
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 5
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: consumer-shard-1-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: data-consumer-shard-1
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Pods
      pods:
        metric:
          name: pubsub_subscription_num_undelivered_messages
        target:
          type: AverageValue
          averageValue: "100"
```

### 4. æ”¹è¿›çš„æ¶ˆè´¹è€…é€»è¾‘

```go
// æ”¯æŒå¤šå®ä¾‹çš„æ¶ˆè´¹è€…
func startConsumer(shardID string) {
    subscriptionName := fmt.Sprintf("data-write-subscription-shard-%s", shardID)

    // é…ç½®å¹¶å‘æ¥æ”¶
    subscription := client.Subscription(subscriptionName)
    subscription.ReceiveSettings.MaxConcurrentHandlers = 10
    subscription.ReceiveSettings.MaxOutstandingMessages = 100

    // å¯åŠ¨å¤šä¸ªgoroutineå¤„ç†æ¶ˆæ¯
    for i := 0; i < runtime.NumCPU(); i++ {
        go func(workerID int) {
            subscription.Receive(ctx, func(ctx context.Context, msg *pubsub.Message) {
                handleMessage(msg, shardID, workerID)
            })
        }(i)
    }
}

func handleMessage(msg *pubsub.Message, shardID string, workerID int) {
    // æ·»åŠ åˆ†å¸ƒå¼é”é˜²æ­¢é‡å¤å¤„ç†
    lockKey := fmt.Sprintf("msg_lock_%s", msg.ID)

    if !acquireDistributedLock(lockKey, 30*time.Second) {
        log.Printf("Message %s already being processed", msg.ID)
        msg.Ack() // å·²è¢«å…¶ä»–å®ä¾‹å¤„ç†
        return
    }
    defer releaseDistributedLock(lockKey)

    // å¹‚ç­‰æ€§æ£€æŸ¥
    if isMessageProcessed(msg.ID) {
        log.Printf("Message %s already processed", msg.ID)
        msg.Ack()
        return
    }

    // å¤„ç†æ¶ˆæ¯
    var data WriteRequest
    if err := json.Unmarshal(msg.Data, &data); err != nil {
        log.Printf("Failed to unmarshal message: %v", err)
        msg.Nack()
        return
    }

    // å†™å…¥æ•°æ®åº“
    if err := writeToDatabase(data, shardID); err != nil {
        log.Printf("Failed to write to database: %v", err)
        msg.Nack()
        return
    }

    // æ ‡è®°æ¶ˆæ¯å·²å¤„ç†
    markMessageProcessed(msg.ID)
    msg.Ack()
}
```

### 5. åˆ†å¸ƒå¼é”å®ç° (ä½¿ç”¨ Redis)

```go
// ä½¿ç”¨Rediså®ç°åˆ†å¸ƒå¼é”
func acquireDistributedLock(key string, expiration time.Duration) bool {
    lockValue := generateUniqueID()

    result := redisClient.SetNX(ctx, key, lockValue, expiration)
    if result.Err() != nil {
        return false
    }

    return result.Val()
}

func releaseDistributedLock(key string) {
    // ä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åŸå­æ€§
    script := `
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
    `
    redisClient.Eval(ctx, script, []string{key}, lockValue)
}
```

## å®Œæ•´çš„é«˜å¯ç”¨æ¶æ„

```mermaid
flowchart TD
    A[Load Balancer] --> B[Kong API Gateway]
    B --> C[API Pods HPA 2-10]

    C --> D[Pub/Sub Topic<br/>3 Ordered Subscriptions]

    D --> E[Shard-1 Subscription]
    D --> F[Shard-2 Subscription]
    D --> G[Shard-3 Subscription]

    E --> H[Consumer-1 Pods<br/>HPA 2-5]
    F --> I[Consumer-2 Pods<br/>HPA 2-5]
    G --> J[Consumer-3 Pods<br/>HPA 2-5]

    H --> K[Redis Distributed Lock]
    I --> K
    J --> K

    H --> L[Cloud SQL Shard-1<br/>with Read Replicas]
    I --> M[Cloud SQL Shard-2<br/>with Read Replicas]
    J --> N[Cloud SQL Shard-3<br/>with Read Replicas]

    subgraph "Monitoring"
        O[Prometheus]
        P[Grafana]
        Q[Alertmanager]
    end

    H --> O
    I --> O
    J --> O
```

## æ•…éšœæ¢å¤æœºåˆ¶

| æ•…éšœåœºæ™¯                 | è§£å†³æ–¹æ¡ˆ                     | æ¢å¤æ—¶é—´ |
| ------------------------ | ---------------------------- | -------- |
| å•ä¸ª Consumer Pod æ•…éšœ   | HPA è‡ªåŠ¨æ‰©å®¹ + å…¶ä»– Pod æ¥ç®¡ | < 30 ç§’  |
| æ•´ä¸ª Shard Consumer æ•…éšœ | æ¶ˆæ¯å †ç§¯ + å‘Šè­¦ + æ‰‹åŠ¨ä»‹å…¥   | < 5 åˆ†é’Ÿ |
| Pub/Sub æ•…éšœ             | GCP è‡ªåŠ¨æ•…éšœè½¬ç§»             | < 1 åˆ†é’Ÿ |
| æ•°æ®åº“ Shard æ•…éšœ        | Read Replica æå‡ä¸º Master   | < 2 åˆ†é’Ÿ |
| Redis é”æœåŠ¡æ•…éšœ         | é™çº§ä¸ºæ— é”æ¨¡å¼ + å¹‚ç­‰æ€§ä¿è¯  | ç«‹å³     |

è¿™æ ·è®¾è®¡å°±æ¶ˆé™¤äº†å•ç‚¹æ•…éšœï¼ŒåŒæ—¶ä¿è¯äº†æ•°æ®ä¸€è‡´æ€§å’Œé«˜å¯ç”¨æ€§ã€‚æ¯ä¸ªç»„ä»¶éƒ½æœ‰å†—ä½™ï¼Œæ•´ä¸ªç³»ç»Ÿå…·å¤‡è‡ªæ„ˆèƒ½åŠ›ã€‚

å¯ä»¥ï¼æœ‰å¤šç§æ–¹å¼åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ§åˆ¶æµé‡åªè·¯ç”±åˆ°ç‰¹å®š Podã€‚ä»¥ä¸‹æ˜¯å‡ ç§å®ç°æ–¹æ¡ˆï¼š

## 1. åŸºäº Session Affinity (æœ€ç®€å•)

### Kubernetes Service é…ç½®

```yaml
# service-with-affinity.yaml
apiVersion: v1
kind: Service
metadata:
  name: data-writer-service
spec:
  selector:
    app: data-writer
  ports:
    - port: 80
      targetPort: 8080
  sessionAffinity: ClientIP # åŸºäºå®¢æˆ·ç«¯IPçš„ä¼šè¯äº²å’Œæ€§
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600 # 1å°æ—¶å†…åŒä¸€IPè·¯ç”±åˆ°åŒä¸€Pod
```

## 2. ä½¿ç”¨ Kong å®ç°ç²¾ç¡®æµé‡æ§åˆ¶

### Kong æ’ä»¶é…ç½®

```yaml
# kong-consumer-groups.yaml
apiVersion: configuration.konghq.com/v1
kind: KongPlugin
metadata:
  name: upstream-routing
plugin: request-transformer
config:
  add:
    headers:
      - "X-Target-Pod:$(headers.user-id | hash % pod-count)"
---
apiVersion: configuration.konghq.com/v1
kind: KongIngress
metadata:
  name: pod-routing
upstream:
  algorithm: consistent-hashing
  hash_on: header
  hash_on_header: X-Target-Pod
```

### è‡ªå®šä¹‰ Kong æ’ä»¶å®ç°

```lua
-- kong-pod-router.lua
local kong = kong
local ngx = ngx

local function route_to_specific_pod()
    local user_id = kong.request.get_header("user-id")
    local operation_type = kong.request.get_header("operation-type")

    if operation_type == "write" and user_id then
        -- åŸºäºç”¨æˆ·IDè®¡ç®—ç›®æ ‡Pod
        local pod_index = tonumber(user_id) % 3 + 1
        kong.service.request.set_header("X-Target-Pod", "pod-" .. pod_index)
    end
end

return {
    PRIORITY = 1000,
    VERSION = "1.0.0",
    access = route_to_specific_pod
}
```

## 3. ä½¿ç”¨ Istio Service Mesh

### DestinationRule é…ç½®

```yaml
# istio-destination-rule.yaml
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: data-writer-dr
spec:
  host: data-writer-service
  subsets:
    - name: pod-1
      labels:
        pod-index: "1"
    - name: pod-2
      labels:
        pod-index: "2"
    - name: pod-3
      labels:
        pod-index: "3"
  trafficPolicy:
    consistentHash:
      httpHeaderName: "user-id"
```

### VirtualService é…ç½®

```yaml
# istio-virtual-service.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: data-writer-vs
spec:
  hosts:
    - data-writer-service
  http:
    - match:
        - headers:
            operation-type:
              exact: "write"
            user-id:
              regex: ".*[0369]$" # ç”¨æˆ·IDæœ«ä½ä¸º0,3,6,9
      route:
        - destination:
            host: data-writer-service
            subset: pod-1
    - match:
        - headers:
            operation-type:
              exact: "write"
            user-id:
              regex: ".*[147]$" # ç”¨æˆ·IDæœ«ä½ä¸º1,4,7
      route:
        - destination:
            host: data-writer-service
            subset: pod-2
    - match:
        - headers:
            operation-type:
              exact: "write"
            user-id:
              regex: ".*[258]$" # ç”¨æˆ·IDæœ«ä½ä¸º2,5,8
      route:
        - destination:
            host: data-writer-service
            subset: pod-3
    - route: # é»˜è®¤è·¯ç”±
        - destination:
            host: data-writer-service
```

## 4. åº”ç”¨å±‚è´Ÿè½½å‡è¡¡æ§åˆ¶

### è‡ªå®šä¹‰è´Ÿè½½å‡è¡¡å™¨

```go
// custom-lb-controller.go
package main

type PodRouter struct {
    podEndpoints map[string][]string
    hashRing     *consistent.Consistent
}

func (pr *PodRouter) RouteRequest(userID string, operationType string) string {
    if operationType == "write" {
        // å†™æ“ä½œè·¯ç”±åˆ°ç‰¹å®šPod
        return pr.getConsistentPod(userID)
    }
    // è¯»æ“ä½œå¯ä»¥è·¯ç”±åˆ°ä»»æ„Pod
    return pr.getRandomPod()
}

func (pr *PodRouter) getConsistentPod(key string) string {
    node, err := pr.hashRing.Get(key)
    if err != nil {
        return pr.getRandomPod()
    }
    return node
}

// HTTPä»£ç†å®ç°
func proxyHandler(w http.ResponseWriter, r *http.Request) {
    userID := r.Header.Get("User-ID")
    operationType := r.Header.Get("Operation-Type")

    targetPod := router.RouteRequest(userID, operationType)

    // åˆ›å»ºåå‘ä»£ç†
    target, _ := url.Parse(fmt.Sprintf("http://%s", targetPod))
    proxy := httputil.NewSingleHostReverseProxy(target)

    // æ·»åŠ è·¯ç”±ä¿¡æ¯åˆ°Header
    r.Header.Set("X-Routed-To", targetPod)

    proxy.ServeHTTP(w, r)
}
```

## 5. åŸºäº Deployment Label çš„ç²¾ç¡®æ§åˆ¶

### åˆ›å»ºå¸¦æ ‡ç­¾çš„ Deployment

```yaml
# labeled-deployments.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-writer-pod-1
spec:
  replicas: 2
  selector:
    matchLabels:
      app: data-writer
      pod-group: "group-1"
  template:
    metadata:
      labels:
        app: data-writer
        pod-group: "group-1"
        pod-index: "1"
    spec:
      containers:
        - name: writer
          image: your-app:latest
          env:
            - name: POD_GROUP
              value: "group-1"
            - name: HANDLED_USER_RANGE
              value: "0-999"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-writer-pod-2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: data-writer
      pod-group: "group-2"
  template:
    metadata:
      labels:
        app: data-writer
        pod-group: "group-2"
        pod-index: "2"
    spec:
      containers:
        - name: writer
          image: your-app:latest
          env:
            - name: POD_GROUP
              value: "group-2"
            - name: HANDLED_USER_RANGE
              value: "1000-1999"
```

### å¯¹åº”çš„å¤šä¸ª Service

```yaml
# group-specific-services.yaml
apiVersion: v1
kind: Service
metadata:
  name: data-writer-group-1
spec:
  selector:
    app: data-writer
    pod-group: "group-1"
  ports:
    - port: 80
      targetPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: data-writer-group-2
spec:
  selector:
    app: data-writer
    pod-group: "group-2"
  ports:
    - port: 80
      targetPort: 8080
```

## 6. å®Œæ•´çš„æµé‡æ§åˆ¶æ¶æ„

```mermaid
flowchart TD
    A[Client Request<br/>Header: user-id, operation-type] --> B[Kong Gateway]

    B --> C{Operation Type?}

    C -->|Read| D[ä»»æ„Pod<br/>è´Ÿè½½å‡è¡¡]
    C -->|Write| E[Hash Routing Logic]

    E --> F{User ID % 3}

    F -->|0| G[Pod Group 1<br/>Service: group-1]
    F -->|1| H[Pod Group 2<br/>Service: group-2]
    F -->|2| I[Pod Group 3<br/>Service: group-3]

    G --> J[Pod-1a, Pod-1b<br/>Handle Users 0,3,6,9...]
    H --> K[Pod-2a, Pod-2b<br/>Handle Users 1,4,7...]
    I --> L[Pod-3a, Pod-3b<br/>Handle Users 2,5,8...]

    J --> M[Database Shard 1]
    K --> N[Database Shard 2]
    L --> O[Database Shard 3]

    subgraph "ç›‘æ§å‘Šè­¦"
        P[Prometheus]
        Q[Grafana Dashboard]
        R[Alert Rules]
    end

    J --> P
    K --> P
    L --> P
```

## å®ç°å»ºè®®ä¼˜å…ˆçº§

| æ–¹æ¡ˆ               | å¤æ‚åº¦ | å¯é æ€§ | æ€§èƒ½  | ç»´æŠ¤æˆæœ¬ | æ¨èåœºæ™¯          |
| ------------------ | ------ | ------ | ----- | -------- | ----------------- |
| Session Affinity   | ğŸŸ¢ ä½  | ğŸŸ¡ ä¸­  | ğŸŸ¢ é«˜ | ğŸŸ¢ ä½    | ç®€å•åœºæ™¯          |
| Kong æ’ä»¶          | ğŸŸ¡ ä¸­  | âœ… é«˜  | âœ… é«˜ | ğŸŸ¡ ä¸­    | API ç½‘å…³å·²ç”¨ Kong |
| Istio Service Mesh | ğŸ”´ é«˜  | âœ… é«˜  | âœ… é«˜ | ğŸ”´ é«˜    | å¾®æœåŠ¡æ¶æ„        |
| åº”ç”¨å±‚ LB          | ğŸŸ¡ ä¸­  | âœ… é«˜  | ğŸŸ¡ ä¸­ | ğŸŸ¡ ä¸­    | è‡ªå®šä¹‰éœ€æ±‚        |
| å¤š Service åˆ†ç»„    | ğŸŸ¢ ä½  | âœ… é«˜  | âœ… é«˜ | ğŸŸ¢ ä½    | **æ¨è PRD ç¯å¢ƒ** |

**å¯¹äºç”Ÿäº§ç¯å¢ƒï¼Œæ¨èä½¿ç”¨"å¤š Service åˆ†ç»„"æ–¹æ¡ˆ**ï¼Œå› ä¸ºå®ƒç®€å•å¯é ï¼Œæ˜“äºç›‘æ§å’Œæ•…éšœæ’é™¤ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å¯ç”¨æ€§ã€‚

# ChatGPT

å¯¹äºè¿è¡Œåœ¨ PRD ç”Ÿäº§ç¯å¢ƒçš„ GKE ,æ¯”å¦‚æˆ‘ä»¬é»˜è®¤ HPA æœ€å°‘ 2 ä¸ª Pod.ä½†æ˜¯æœ‰è¿™æ ·ä¸šåŠ¡é€»è¾‘,æ¯”å¦‚æˆ‘çš„ Pod é‡Œé¢æœ‰ä¸€ä¸ªå†™æ•°æ®åº“çš„ API, é‚£ä¹ˆå¦‚æœåŒæ—¶éƒ½è¿è¡Œçš„è¯.é‚£ä¹ˆå¯èƒ½ä¼šå¼•èµ·å†™æ•°æ®æ··ä¹±?ä½†æ˜¯æˆ‘è¿™ä¸ªä»…ä»…æ˜¯ä¸€ä¸ªåœºæ™¯è®¾æƒ³.å…¶å®æ ¸å¿ƒå°±æ˜¯å¤š Pod åŒæ—¶å†™æ•°æ®.å¸¦æ¥çš„æ•°æ®å¯èƒ½å†²çªçš„é—®é¢˜.å¯¹äºè¿™ç§åœºæ™¯.ä¸€èˆ¬æœ‰ä»€ä¹ˆå¯¹åº”çš„è§£å†³æ–¹æ¡ˆ? å› ä¸ºå¦‚æœæˆ‘åªè¿è¡Œä¸€ä¸ª Pod.é‚£ä¹ˆ Pod å°±æ²¡æœ‰é«˜å¯ç”¨äº†

ä½ æåˆ°çš„**å¤š Pod é«˜å¯ç”¨ä¸‹å†™æ•°æ®åº“å¼•å‘æ•°æ®å†²çªçš„é—®é¢˜**ï¼Œæ˜¯ç”Ÿäº§ç¯å¢ƒä¸­å¸¸è§çš„è®¾è®¡éš¾é¢˜ã€‚æ ¸å¿ƒæŒ‘æˆ˜æ˜¯ï¼š**å¦‚ä½•åœ¨ä¿æŒæ°´å¹³æ‰©å±•ï¼ˆå¤šå‰¯æœ¬ã€é«˜å¯ç”¨ï¼‰çš„åŒæ—¶ï¼Œç¡®ä¿å†™æ“ä½œçš„æ•°æ®ä¸€è‡´æ€§å’Œå¹‚ç­‰æ€§**ã€‚

â¸»

**ğŸ’¡ åœºæ™¯é—®é¢˜å½’çº³**

â€¢ **å¤šå‰¯æœ¬ Pod å†™æ•°æ®åº“**ï¼šå¯èƒ½å‡ºç°é‡å¤å†™å…¥ã€å†™é¡ºåºé”™è¯¯ã€èµ„æºç«äº‰ç­‰é—®é¢˜ã€‚

â€¢ **ä¸èƒ½åªè·‘ä¸€ä¸ª Pod**ï¼šå¦åˆ™å°±å¤±å»äº†å®¹ç¾èƒ½åŠ›ï¼ˆæ¯”å¦‚ HPAã€è‡ªåŠ¨ failoverï¼‰ã€‚

â€¢ **å…¸å‹ä¸šåŠ¡åœºæ™¯**ï¼š

â€¢ åˆ›å»ºè®¢å•ï¼ˆä¸èƒ½é‡å¤ï¼‰

â€¢ æ›´æ–°åº“å­˜ï¼ˆä¸èƒ½å‡ºç°ç«æ€ï¼‰

â€¢ å†™å…¥æ—¥å¿—ï¼ˆè¦æ±‚æ—¶åºã€å¹‚ç­‰ï¼‰

â¸»

**âœ… è§£å†³æ–¹æ¡ˆæ¦‚è§ˆ**

| æ–¹æ¡ˆç±»åˆ«           | å…·ä½“æ–¹æ¡ˆ                     | é€‚ç”¨åœºæ™¯                         |
| ------------------ | ---------------------------- | -------------------------------- |
| æ•°æ®åº“å±‚æ§åˆ¶       | ä¹è§‚é”ã€æ‚²è§‚é”               | å•è¡¨å¹¶å‘å†™è¾ƒé«˜ã€æ›´æ–°å†²çªå¯èƒ½æ€§å¤§ |
| åº”ç”¨å±‚æ§åˆ¶         | å¹‚ç­‰æ€§è®¾è®¡ã€å…¨å±€é”ã€å¹‚ç­‰ Key | REST API æ¥å£ã€é¿å…é‡å¤å†™å…¥      |
| åˆ†å¸ƒå¼åè°ƒæœºåˆ¶     | leader election / åˆ†å¸ƒå¼é”   | Kafka æ¶ˆè´¹ã€å®šæ—¶ä»»åŠ¡ã€åºåˆ—ç”Ÿæˆç­‰ |
| æ•°æ®ä¸€è‡´æ€§æ¶æ„ä¼˜åŒ– | ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—ã€Saga/è¡¥å¿æœºåˆ¶  | å¼‚æ­¥å†™æ“ä½œã€å¾®æœåŠ¡äº‹åŠ¡           |
| Kubernetes æ§åˆ¶    | podAffinityã€HPA tuningã€PDB | å¼ºåˆ¶åŒä¸€ä»»åŠ¡åªç”±ä¸€ä¸ª Pod æ‰§è¡Œ    |

â¸»

**ğŸ¯ å…¸å‹è®¾è®¡æ–¹æ¡ˆè¯´æ˜**

**1. å¹‚ç­‰æ€§è®¾è®¡ï¼ˆå¼ºçƒˆæ¨èï¼‰**

**é€‚ç”¨ï¼š** å¤š Pod å¯¹åŒä¸€ä¸ªå†™æ¥å£å‘è¯·æ±‚ï¼Œä½†å¸Œæœ›å†™å…¥å”¯ä¸€è®°å½•æˆ–é¿å…é‡å¤ã€‚

**æ–¹å¼ï¼š**

â€¢ ä¸ºæ¯ä¸ªå†™è¯·æ±‚è®¾ç½® **å”¯ä¸€å¹‚ç­‰ Keyï¼ˆidempotent keyï¼‰**ï¼ˆå¦‚ UUIDã€è®¢å•å·ï¼‰

â€¢ åœ¨æ•°æ®åº“åŠ å”¯ä¸€çº¦æŸï¼Œå†™å¤±è´¥æ—¶è¿”å›é‡å¤é”™è¯¯

â€¢ æ¥å£è¿”å›å·²å†™å…¥è®°å½•ï¼ˆä¸é‡è¯•ï¼‰

-- ä»¥è®¢å•åˆ›å»ºä¸ºä¾‹

```sql
CREATE TABLE orders (
order_id VARCHAR PRIMARY KEY,
user_id VARCHAR,
product_id VARCHAR,
created_at TIMESTAMP DEFAULT now()
);
```

```java
// æ¥å£ä¼ªä»£ç 
if (db.exists(order_id)) {
return db.get(order_id);
} else {
db.insert(order);
return order;
}

```

â¸»

**2. åŸºäºæ•°æ®åº“çš„æ‚²è§‚é”/ä¹è§‚é”**

**é€‚ç”¨ï¼š** å¹¶å‘å†™å…¥ç›¸åŒæ•°æ®è®°å½•æ—¶ï¼Œè¦æ±‚ä¸¥æ ¼ä¸€è‡´æ€§ã€‚

â€¢ **æ‚²è§‚é”**ï¼šSELECT ... FOR UPDATEï¼Œé¿å…å¹¶å‘æ›´æ–°

â€¢ **ä¹è§‚é”**ï¼šåŠ  version å­—æ®µï¼Œæ›´æ–°æ—¶ç‰ˆæœ¬å¯¹æ¯”ï¼Œä¸ä¸€è‡´åˆ™å¤±è´¥é‡è¯•

-- ä¹è§‚é”ç¤ºä¾‹

```sql
UPDATE inventory
SET stock = stock - 1, version = version + 1
WHERE product_id = '123' AND version = 10;
```

â¸»

**3. å¼•å…¥åˆ†å¸ƒå¼é”ï¼ˆå¦‚ Redisã€etcdï¼‰**

**é€‚ç”¨ï¼š** ä»»åŠ¡å¿…é¡»ä¸²è¡Œæ‰§è¡Œï¼ˆä¾‹å¦‚å®šæ—¶ä»»åŠ¡ã€å”¯ä¸€å¤„ç†å™¨ï¼‰

â€¢ å¤š Pod åŒæ—¶è¿è¡Œï¼Œä½†æŸä¸€ç±»å†™ä»»åŠ¡é€šè¿‡ **é”åè°ƒåªç”±ä¸€ä¸ª Pod æ‰§è¡Œ**

â€¢ å¯ä½¿ç”¨ Redlockï¼ˆRedis åˆ†å¸ƒå¼é”ï¼‰ã€K8S leader election

# Pod A æˆåŠŸæ‹¿åˆ° Redis é”åæ‰èƒ½æ‰§è¡Œå†™æ“ä½œ

SETNX lock:write:job "pod-a" EX 10

â¸»

**4. Leader Election + ä»»åŠ¡éš”ç¦»**

**é€‚ç”¨ï¼š** å®šæ—¶å†™ä»»åŠ¡ã€æ‰¹é‡å¤„ç†ã€å¯¼å…¥æ•°æ®ç­‰ä»»åŠ¡

â€¢ åœ¨å¤š Pod ä¸­é€‰å‡ºâ€œLeaderâ€æ¥æ‰§è¡Œæ•æ„Ÿå†™å…¥

â€¢ Kubernetes ä¸­å¯ç”¨ ConfigMap æˆ–ç¬¬ä¸‰æ–¹ç»„ä»¶ï¼ˆå¦‚ [kube-leader-elector](https://github.com/kubernetes-client/python/blob/master/examples/leader_election.py)ï¼‰
```yaml
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - podAffinityTerm:
          labelSelector:
            matchLabels:
              app: db-writer
          topologyKey: "kubernetes.io/hostname"
```
â¸»

**5. é€šè¿‡å¼‚æ­¥é˜Ÿåˆ—å®ç°ä¸²è¡Œå†™å…¥**

**é€‚ç”¨ï¼š** é«˜å¹¶å‘åœºæ™¯ï¼Œä¾‹å¦‚è®¢å•ã€æ”¯ä»˜ç­‰

â€¢ å¤š Pod æ¥æ”¶è¯·æ±‚ï¼Œå†™å…¥ Kafkaã€Pub/Sub ç­‰é˜Ÿåˆ—

â€¢ ç‹¬ç«‹çš„ Consumer Pod æŒ‰é¡ºåºæ¶ˆè´¹å†™å…¥æ•°æ®åº“ï¼ˆå¯é…åˆå¹‚ç­‰æ€§ï¼‰

```mermaid
graph TD;

A[Client Request] --> B[API Pod A/B];

B --> C[Kafka/Queue];

C --> D[Writer Pod];

D --> E[DB];

```

â¸»

**âœ… æœ€ä½³å®è·µå»ºè®®ï¼ˆç”Ÿäº§ï¼‰**

1. **ä¼˜å…ˆä½¿ç”¨å¹‚ç­‰æ€§è®¾è®¡**ï¼šè®¾è®¡æ¥å£æ—¶å°±è€ƒè™‘é‡å¤è¯·æ±‚/é‡å¤å†™çš„å»é‡é€»è¾‘

2. **æ•æ„Ÿé€»è¾‘å•ç‹¬æœåŠ¡åŒ–**ï¼šæ¯”å¦‚å†™è®¢å•çš„æœåŠ¡éš”ç¦»ï¼Œé¿å…å…¬å…±é€»è¾‘å½±å“

3. **ä»»åŠ¡å†™å…¥é€šè¿‡é˜Ÿåˆ—ä¸²è¡ŒåŒ–**ï¼šæ¶ˆæ¯é˜Ÿåˆ—å¯è§£è€¦+é«˜å¯ç”¨

4. **é¿å…åªé å• Pod æ‰§è¡Œ**ï¼šå¤±å»äº† Kubernetes é«˜å¯ç”¨èƒ½åŠ›

5. **ç›‘æ§å†²çªé”™è¯¯ä¸é”ç«äº‰**ï¼šç¡®ä¿å†™å…¥ä¸ä¼š silently fail

â¸»

å¦‚ä½ å¸Œæœ›æˆ‘æ ¹æ®ä½ å…·ä½“ä¸šåŠ¡åœºæ™¯ï¼ˆæ¯”å¦‚ Java æˆ– Spring Bootï¼‰è¿›ä¸€æ­¥ç»†åŒ–è®¾è®¡ï¼Œæˆ‘å¯ä»¥å¸®ä½ å‡ºå…·ä½“æ¨¡æ¿æˆ–å®ç°ç¤ºä¾‹ã€‚æ˜¯å¦éœ€è¦ï¼Ÿ

æ˜¯çš„ï¼Œ**åœ¨ GKE ä¸­ç»“åˆä½¿ç”¨ Google Cloud Pub/Sub æ˜¯å¤„ç†å¤š Pod å†™æ•°æ®åº“å†²çªã€å®ç°é«˜å¹¶å‘å®‰å…¨å†™å…¥çš„æä½³è§£å†³æ–¹æ¡ˆä¹‹ä¸€**ï¼Œç‰¹åˆ«é€‚åˆä»¥ä¸‹åœºæ™¯ï¼š

---

## **âœ… ä½¿ç”¨ Pub/Sub çš„ä¼˜åŠ¿ï¼ˆç‰¹åˆ«é€‚ç”¨äº GKEï¼‰**

| **ä¼˜åŠ¿**                                | **è¯´æ˜**                                                 |
| --------------------------------------- | -------------------------------------------------------- |
| **å¤©ç„¶è§£è€¦**                            | GKE ä¸­å¤šä¸ª Pod å¯ä»¥å¹¶å‘å‘å¸ƒæ¶ˆæ¯ï¼Œä¸éœ€è¦ç›´æ¥å†™æ•°æ®åº“      |
| **é«˜å¯ç”¨ + é«˜æ‰©å±•**                     | Pub/Sub æ˜¯æ‰˜ç®¡æœåŠ¡ï¼Œæ”¯æŒæ°´å¹³æ‰©å±•ï¼Œä¸æ˜“æˆä¸ºç“¶é¢ˆ           |
| **å¹‚ç­‰å†™å…¥æ›´æ˜“å®ç°**                    | ä½¿ç”¨ messageId æˆ–ä¸šåŠ¡è‡ªå®šä¹‰ deduplication key åšå¹‚ç­‰å»é‡ |
| **æŒä¹…åŒ–ä¿éšœ**                          | æ¶ˆæ¯é»˜è®¤å­˜å‚¨ 7 å¤©ï¼Œé¿å…ç¬æ—¶ç³»ç»Ÿå¼‚å¸¸ä¸¢æ•°æ®                |
| **ä¸ GKE/GCS/Cloud Functions é›†æˆç´§å¯†** | ä½ å¯ä»¥ç”¨ Cloud Run / GKE çš„åå°è®¢é˜…å†™é€»è¾‘                |

---

## **ğŸ“Œ æ¨èæ¶æ„æ¨¡å¼ï¼šPub/Sub + Worker å†™å…¥ DB**

```mermaid
graph TD;
    A[Client Request Pod A/B] --> B[Publish to Pub/Sub];
    B --> C[Subscriber Pod GKE Deployment];
    C --> D[Write to Database];
```

### **è¯´æ˜ï¼š**

- Client è¯·æ±‚ç”±å¤šä¸ª GKE Pod å¤„ç†ï¼Œå‘å¸ƒå†™å…¥ä»»åŠ¡åˆ° Pub/Subï¼ˆé¿å…ç›´æ¥å†™ DBï¼‰
- ç‹¬ç«‹çš„ Subscriber Deploymentï¼ˆå¯ä»¥æœ‰å¤šä¸ª Podï¼‰æ¶ˆè´¹æ¶ˆæ¯ï¼Œé¡ºåºæˆ–å¹¶å‘å†™å…¥ DB
- å¯åœ¨ Subscriber ä¸­åŠ å…¥å¹‚ç­‰æ€§æ ¡éªŒé€»è¾‘ã€é‡è¯•æœºåˆ¶ã€æ­»ä¿¡é˜Ÿåˆ—å¤„ç†

---

## **ğŸ”§ å®ç°å»ºè®®**

### **1.**Â 

### **Producer ç«¯ï¼ˆGKE API Podï¼‰**

```
# ç¤ºä¾‹: å°†è®¢å•å†™å…¥ pub/sub
publisher = pubsub_v1.PublisherClient()
topic_path = publisher.topic_path('your-project-id', 'order-topic')
data = json.dumps(order_payload).encode("utf-8")
future = publisher.publish(topic_path, data, order_id="123456")
```

### **2.**Â 

### **Consumer ç«¯ï¼ˆç‹¬ç«‹ GKE Worker æˆ– Cloud Runï¼‰**

```
# ç¤ºä¾‹: æ¥æ”¶è®¢é˜…æ¶ˆæ¯å¹¶å†™å…¥æ•°æ®åº“
def callback(message):
    payload = json.loads(message.data)
    order_id = payload["order_id"]
    # å¹‚ç­‰æ£€æŸ¥
    if not db.exists(order_id):
        db.insert(payload)
    message.ack()
```

ä½ å¯ä»¥é€šè¿‡ GKE çš„ Deployment å¯å¤šä¸ª Pod æ¶ˆè´¹è¯¥ Topicï¼Œä¿æŒæ¶ˆè´¹èƒ½åŠ›å†—ä½™ã€‚

---

## **ğŸ§± å¯é€‰å¢å¼ºç»„ä»¶**

| **åŠŸèƒ½** | **å·¥å…·/å»ºè®®**                            |
| -------- | ---------------------------------------- |
| å¹‚ç­‰å»é‡ | æ•°æ®åº“ä¸»é”®ã€å¹‚ç­‰ keyã€Redis å¸ƒéš†è¿‡æ»¤å™¨   |
| é”™è¯¯è¿½è¸ª | Pub/Sub Dead Letter Topicï¼ˆDLTï¼‰         |
| æ¶ˆè´¹ç›‘æ§ | Cloud Monitoring + Log-based Metric      |
| è‡ªåŠ¨å¼¹æ€§ | Worker Pod é… HPAï¼ˆæ ¹æ® CPU/MQ backlogï¼‰ |
| é™æµ     | ç»“åˆ Cloud Tasks æˆ– Token Bucket         |

---

## **âœ… æ€»ç»“ï¼šä¸ºä»€ä¹ˆ Pub/Sub + GKE æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é€‰æ‹©ï¼Ÿ**

| **ç‰¹æ€§**             | **è¯´æ˜**                                        |
| -------------------- | ----------------------------------------------- |
| **å¹³å°å†…åŸç”Ÿæ•´åˆ**   | ä¸ GKEã€IAMã€Cloud Loggingã€Monitoring é›†æˆé¡ºç•… |
| **è§£è€¦ä¸šåŠ¡å†™å…¥å‹åŠ›** | æ¥æ”¶è¯·æ±‚çš„ Pod åªè´Ÿè´£å‘é€æ¶ˆæ¯ï¼Œä¸å‚ä¸å¤æ‚å†™æ“ä½œ |
| **å®¹é”™èƒ½åŠ›å¼º**       | æ”¯æŒé‡è¯•ã€æ­»ä¿¡é˜Ÿåˆ—ï¼Œé¿å…æ•°æ®ä¸¢å¤±                |
| **é€‚é…é«˜å¹¶å‘æ¶æ„**   | å¯åŠ¨æ€æ‰©å®¹ Subscriber Podï¼ˆæ”¯æŒ HPAï¼‰           |

---

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥å¸®ä½ å‡ºä¸€ä¸ª **Pub/Sub + GKE Subscriber Deployment çš„ YAML æ¨¡æ¿** æˆ– Python ç¤ºä¾‹ç¨‹åºï¼Œå¿«é€Ÿæ„å»ºè¿™ä¸ªæ¶æ„ã€‚æ˜¯å¦éœ€è¦ï¼Ÿ
å¥½çš„ï¼Œä»¥ä¸‹æ˜¯ä¸€ä¸ª**å®Œæ•´çš„ Google Cloud Pub/Sub + GKE ä¸­ä½¿ç”¨ Deployment æ¶ˆè´¹æ¶ˆæ¯å¹¶å†™å…¥æ•°æ®åº“çš„ç¤ºä¾‹**ï¼ŒåŒ…å«ï¼š

1. Pub/Sub Topic + Subscription åˆ›å»º
2. Python æ¶ˆè´¹è„šæœ¬
3. Dockerfile
4. GKE Deployment YAMLï¼ˆä½¿ç”¨ Secret + ServiceAccount è®¤è¯ï¼‰
5. å»ºè®®æ€§ HPA è®¾ç½®ï¼ˆå¯é€‰ï¼‰

---

## **ğŸ”§ å‰æ**

- å·²å¯ç”¨ Pub/Sub API
- å·²åˆ›å»º Topicï¼ˆä¾‹å¦‚ï¼šorder-topicï¼‰
- å·²ä¸º GKE é…ç½®å¥½è®¿é—®æƒé™ï¼ˆWorkload Identity æˆ– GCP ServiceAccountï¼‰

---

## **1. Python æ¶ˆè´¹è„šæœ¬ï¼ˆsubscriber.pyï¼‰**

```Python
import os
import json
from google.cloud import pubsub_v1
from google.cloud import firestore

# è®¾ç½® Google åº”ç”¨å‡­è¯ï¼ˆå®¹å™¨å†…ç”¨ Workload Identity ä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®ï¼‰
project_id = os.environ["GCP_PROJECT"]
subscription_id = os.environ["SUBSCRIPTION_ID"]
db = firestore.Client()

def callback(message: pubsub_v1.subscriber.message.Message):
    try:
        data = json.loads(message.data.decode("utf-8"))
        order_id = data["order_id"]

        # å¹‚ç­‰æ€§åˆ¤æ–­
        doc_ref = db.collection("orders").document(order_id)
        if not doc_ref.get().exists:
            doc_ref.set(data)
            print(f"Inserted order {order_id}")
        else:
            print(f"Duplicate order {order_id} skipped.")

        message.ack()
    except Exception as e:
        print(f"Error: {e}")
        message.nack()

if __name__ == "__main__":
    subscriber = pubsub_v1.SubscriberClient()
    subscription_path = subscriber.subscription_path(project_id, subscription_id)
    streaming_pull_future = subscriber.subscribe(subscription_path, callback=callback)

    print("Listening for messages...")
    try:
        streaming_pull_future.result()
    except KeyboardInterrupt:
        streaming_pull_future.cancel()
```

---

## **2. Dockerfile**

```Dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY subscriber.py .

RUN pip install --no-cache-dir google-cloud-pubsub google-cloud-firestore

CMD ["python", "subscriber.py"]
```

---

## **3. GKE Deployment ç¤ºä¾‹ï¼ˆsubscriber-deployment.yamlï¼‰**

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pubsub-subscriber
  labels:
    app: pubsub-subscriber
spec:
  replicas: 2
  selector:
    matchLabels:
      app: pubsub-subscriber
  template:
    metadata:
      labels:
        app: pubsub-subscriber
    spec:
      serviceAccountName: gke-pubsub-access-sa  # Workload Identity ç»‘å®šçš„ SA
      containers:
        - name: subscriber
          image: gcr.io/YOUR_PROJECT_ID/pubsub-subscriber:latest
          env:
            - name: GCP_PROJECT
              value: "YOUR_PROJECT_ID"
            - name: SUBSCRIPTION_ID
              value: "order-topic-sub"
          resources:
            limits:
              memory: "256Mi"
              cpu: "200m"
```

> âš ï¸ è¯·æ›¿æ¢ YOUR_PROJECT_ID å’Œè®¢é˜…åç§°ä¸ºä½ å®é™…çš„å€¼ã€‚

---

## **4. å¯é€‰ HPA é…ç½®ï¼ˆæŒ‰ CPU æˆ–è‡ªå®šä¹‰æŒ‡æ ‡ï¼‰**

```
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pubsub-subscriber-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: pubsub-subscriber
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 60
```

---

## **5. Pub/Sub Subscription åˆ›å»ºï¼ˆå‘½ä»¤ï¼‰**

```
# åˆ›å»º Topicï¼ˆå¦‚æœè¿˜æ²¡åˆ›å»ºï¼‰
gcloud pubsub topics create order-topic

# åˆ›å»º Subscription
gcloud pubsub subscriptions create order-topic-sub \
  --topic=order-topic \
  --ack-deadline=60
```

---

## **âœ… æ€»ç»“**

ä½ ç°åœ¨æ‹¥æœ‰äº†ä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯æµç¨‹ï¼š

```mermaid
graph TD;
    A[API Pod å‘å¸ƒæ¶ˆæ¯] --> B[Pub/Sub Topic];
    B --> C[GKE Subscriber Pod];
    C --> D[Firestore/Database];
```

- ä¸šåŠ¡é€»è¾‘æ— éœ€ç›´æ¥å†™åº“ï¼Œåªå‘æ¶ˆæ¯
- å†™å…¥é€»è¾‘é›†ä¸­å¤„ç†ï¼Œå¯æ§ã€å¹‚ç­‰ã€æ˜“è§‚å¯Ÿ
- æ”¯æŒ HPAï¼Œé«˜å¯ç”¨ä¸å¯æ‰©å±•å…¼å¾—

---

æ˜¯å¦éœ€è¦æˆ‘å¸®ä½ åˆ›å»º Cloud Build CI/CD é…ç½®ï¼ˆcloudbuild.yamlï¼‰æˆ– Terraform èµ„æºå®šä¹‰æ¥è‡ªåŠ¨åŒ–è¿™å¥—æµç¨‹ï¼Ÿ
