这个问题你抓得**非常准**，本质上不是 _Python 怎么改_，而是：

> **“异常数据到底该不该存在生产系统里？谁来兜底？修数据还是绕数据？”**

我按**原则 + GCP 实践 + 可落地的决策框架**来回答，你可以直接拿去当内部共识或设计原则。

---

# **一、问题本质（先定性）**

你当前的链路可以抽象成：

```
User API
  ↓
GKE Pod (Python Collector)
  ↓
BigQuery (事实数据)
  ↑
Firestore (维表 / 元数据)
  ↓
Looker Studio (消费层)
```

现在的问题是：

- **异常数据已经进入了“生产事实层（BigQuery）”**

- 报表层才暴露问题

- 当前的“解决方案”是：

    👉 **在 Python 里 special-case 这些异常**

你直觉觉得不舒服，这是完全正确的 👍

因为这已经违反了**数据平台的几个核心原则**。

---

# **二、核心结论（先给你一句话版本）**

> **最佳实践一定不是在报表或脚本里“容忍垃圾数据”，**

> **而是：**

> 

> **在数据进入生产事实层之前，完成“数据质量裁决”。**

换句话说：

|**层级**|**是否允许异常数据**|**责任**|
|---|---|---|
|数据采集层|❌ 不应该|Producer 责任|
|生产事实层（BQ）|❌ 绝对不应该|平台责任|
|隔离/错误区|✅ 可以|运维 & 数据治理|
|报表层|❌ 不兜底|Consumer|

---

# **三、为什么「直接在 Python 里绕过」不是最佳实践**

你现在的方案属于 **Symptom Fix（症状修复）**，问题在于：

### **1️⃣ 语义污染（Semantic Corruption）**

```
if abnormal_case:
    fix_or_skip()
```

长期会导致：

- 代码变成“历史异常博物馆”

- 新人根本不知道哪些数据是“正常世界观”

- **代码逻辑 ≠ 业务真实规则**

---

### **2️⃣ 数据不可追溯**

当老板/安全/审计问你：

> “这份 Looker 报表的数据是 100% 真实的吗？”

你无法回答：

- 哪些被修复了？

- 修复规则是谁定的？

- 是否全量一致？

这是 **数据治理上的硬伤**。

---

### **3️⃣ 报表信任度崩塌（这一点很现实）**

Looker Studio 一旦出现：

- 数字跳变

- 同口径前后不一致

最终结局通常是：

> “大家开始用 Excel 私算一份”

这是数据平台**最失败的结局**。

---

# **四、行业通用的「正确分层模型」**

这是你们现在**应该对齐的模型**（非常 GCP-friendly）：

## **1️⃣ 数据分区原则（强烈建议）**

```
Raw Layer        (原始数据，不改)
│
├── Clean Layer  (通过规则的数据，生产使用)
│
└── Quarantine   (异常数据，隔离)
```

### **在 GCP 里可以这样落地：**

|**层**|**实现方式**|
|---|---|
|Raw|BigQuery 原始表（append-only）|
|Clean|BigQuery 标准化表|
|Quarantine|单独 Dataset（_invalid /_quarantine）|

---

## **2️⃣ Python Collector 的**

## **唯一职责**

> **不是“修数据”，而是“裁决数据”**

### **推荐逻辑（原则版）**

```
收到一条数据
  ↓
Schema 校验
  ↓
业务规则校验
  ↓
├─ 合格 → Clean Table
└─ 不合格 → Quarantine Table + 原因
```

⚠️ 注意：

**不是丢弃，是隔离 + 记录原因**

---

# **五、什么情况下「修数据」是合理的？**

这是一个你现在就能用的**决策表** 👇

|**场景**|**是否允许修**|**原因**|
|---|---|---|
|字段缺失但可推导|✅|技术噪音|
|时区 / 格式错误|✅|采集问题|
|用户非法值|❌|业务错误|
|跨系统语义冲突|❌|源系统 Bug|
|Firestore 旧版本字段|⚠️|需版本控制|

**关键原则**：

> ✅ 可以修 **“技术错误”**

> ❌ 不要修 **“业务错误”**

---

# **六、异常数据应该怎么“活着”？**

不是删除，而是 **可观测地活着**。

### **推荐你至少做到这三点：**

#### **1️⃣ Quarantine 表字段设计**

|**字段**|**说明**|
|---|---|
|raw_payload|原始数据|
|error_type|枚举（schema / business / unknown）|
|error_reason|人可读|
|detected_at|时间|
|source|pod / service|

---

#### **2️⃣ 监控（非常重要）**

- BigQuery：异常行数 / 比例

- Cloud Monitoring：异常突增报警

- SLO 级别：

    > “异常数据 < 0.1%”

---

#### **3️⃣ 数据回补能力（关键）**

当你修复 Python 逻辑后：

```
Quarantine → Reprocess → Clean
```

而不是 **永远丢失**。

---

# **七、Looker Studio 的正确角色**

Looker Studio **不应该承担任何数据修复职责**。

它应该：

- **只连 Clean Layer**

- 永远假设数据是“可信的”

如果 Looker 需要写 IF / CASE 来兜底：

👉 **说明上游已经失败了**

---

# **八、给你一个“可以对外说”的总结版本**

你可以直接用这段话 👇

> 我们的数据平台遵循“生产事实层不可污染”的原则。

> 所有异常数据在进入 BigQuery 生产表之前会被检测并隔离，

> 而不是在消费层或脚本中隐式修复。

> 这样可以保证数据口径一致、可追溯，并支持后续数据回补。

---

# **九、如果你愿意，下一步我可以帮你做的**

你这个问题已经到了**架构层**，不是脚本层了，我可以继续帮你：

1. **设计 BigQuery Dataset 分层规范**

2. **Python Collector 的校验模板**

3. **异常数据的 SLO / 告警设计**

4. **如何跟安全 / 审计解释“为什么保留异常数据”**

5. **Firestore → BQ 联合查询的“脏数据防扩散”方案**

你想从哪一块继续拆？
